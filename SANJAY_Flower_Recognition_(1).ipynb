{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49u0Ty8GAKqb"
   },
   "source": [
    "# **DETAILS**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   **NAME** : R.SANJAY\n",
    "\n",
    "   **EMAIL** : sanjay.r030303@gmail.com\n",
    "\n",
    "**DOMAIN** : DataScience\n",
    "\n",
    "\n",
    "\n",
    "**PROJECT TITLE** : Flower Recognition / Detection\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBk0onPnCUfW"
   },
   "source": [
    "# **ABSTRACT**\n",
    "This project is flower recognition/Detection . This tell the flower name based on the user input . These Type of projects will help to understand about the Neural Network and How its work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZiEXqQU1U4YN"
   },
   "source": [
    "# IMPORTING THE LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VKLA51X2fwWo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import cv2\n",
    "import shutil\n",
    "import random as rn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwfqNRYZeSN2"
   },
   "source": [
    "# **Defining the Dataset**\n",
    "\n",
    "link : https://drive.google.com/drive/folders/180ihV2TuLXwsMwvbktJr-wDCgfkYGQH_?usp=sharing\n",
    "\n",
    "**PLEASE GIVE CORRECT DIRECTORY LOCATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "aqm-M-d0eXW_"
   },
   "outputs": [],
   "source": [
    "data_directory =\"/content/drive/MyDrive/Project 2 Dataset\" # directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YbvSXJo6dcGA",
    "outputId": "d58c8128-8a94-4fc2-d6f8-50d69fe4069f"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (3867108699.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [12]\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(os.listdir(\"C:\\Users\\Dharmaraj\\Desktop\\Project 2 Dataset\")) #showing the directory inside data_directory\u001b[0m\n\u001b[1;37m                                                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"/content/drive/MyDrive/Project 2 Dataset\")) #showing the directory inside data_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQH7UbUAerga"
   },
   "source": [
    "Defining the Image Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cqK8K_Bvdfon"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAfWjo3Zi9D4"
   },
   "source": [
    "splitting Dataset - 80% for training and 20% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwGX-FcOevqI",
    "outputId": "62539b38-47bd-47d5-d654-f94c3fcdf91e"
   },
   "outputs": [],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_directory,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RJO7XHFyfK9a",
    "outputId": "8d222e97-494e-4d12-ba61-82932ce8fb42"
   },
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_directory,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "um6MEewmljBU"
   },
   "source": [
    "The order of the class name is alphabet order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TjpbhzeGfOMO",
    "outputId": "e2c0a704-3a88-45aa-bf3f-599e15084b0b"
   },
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "# This will arrange the class names in alphabetical order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XL-0dAJsf4lf"
   },
   "source": [
    "# **Visualizing the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "id": "jnD7Q0LbfhFY",
    "outputId": "cf092c0c-adc9-473d-a7c6-7ca3a97b0432"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_RoonXdfgBiP",
    "outputId": "4f4caf2c-ae27-40cc-a4b2-b9fa4a64c0b3"
   },
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OF4akQ9XmntV"
   },
   "source": [
    "The image_batch is a tensor of the shape (32, 180, 180, 3). This is a batch of 32 images of shape 180x180x3 . The label_batch is a tensor of the shape (32,), these are corresponding labels to the 32 images.call .numpy() on the image_batch and labels_batch tensors to convert them to a numpy.ndarray."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJAQeQS7m2Qn"
   },
   "source": [
    "**Configure the dataset for performance:**\n",
    "\n",
    "doing buffered prefetching.With this we can yield data from disk without having i/o become blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dCS5RxnNgc2i"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gY0X3kvgmTy"
   },
   "source": [
    "Standardize the data:\n",
    "\n",
    "The RGB channel values are in the [0, 255] range. This is not ideal for a neural network; in general we should seek to make our input values small. Here,  we standardize values to be in the [0, 1] range by using a Rescaling layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQVPmxO2gkNa"
   },
   "outputs": [],
   "source": [
    "normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gsJ_cInMgrIE",
    "outputId": "18aeb5b6-db61-4511-ddbb-ee79429ce42d"
   },
   "outputs": [],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJQCwIgigvwO"
   },
   "source": [
    "**Create the model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "slS-MxkggtV5"
   },
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "model = Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKgf3OLwokDG"
   },
   "source": [
    "compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2dbWOIztg1Rs"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L05SQAWrg1dU",
    "outputId": "f56a8364-2c77-4281-93cd-d5a11ca061fa"
   },
   "outputs": [],
   "source": [
    "epochs=10\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7lylwnB9orDQ"
   },
   "source": [
    "Visualize training results:\n",
    "\n",
    "Create plots of loss and accuracy on the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "XBxXAzMrg2P5",
    "outputId": "fef655fd-b219-41b6-af15-a92d168fe15b"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKNXt5-npf2W"
   },
   "source": [
    "**Overfitting:**\n",
    "\n",
    "In the plots above, the training accuracy is increasing linearly over time, whereas validation accuracy stalls around 60% in the training process. Also, the difference in accuracy between training and validation accuracy is noticeable . It is a sign of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYmO5mw6pf_i"
   },
   "source": [
    "**Data augmentation:**\n",
    "\n",
    "Overfitting generally occurs when there are a small number of training examples. Data augmentation takes the approach of generating additional training data from your existing examples by augmenting them using random transformations that yield believable-looking images. This helps expose the model to more aspects of the data and generalize better.\n",
    "\n",
    "Here we will implement data augmentation using the layers from tf.keras.layers.experimental.preprocessing. These can be included inside our model like other layers, and run on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kH7lvGyyg2TT"
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
    "                                                 input_shape=(img_height, \n",
    "                                                              img_width,\n",
    "                                                              3)),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEl9XHKGo-yM"
   },
   "source": [
    "Few augmented examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "id": "T_kzOl5Fg2Xc",
    "outputId": "3280c7b2-6590-43f7-8ba6-d774972070ce"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    augmented_images = data_augmentation(images)\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gyYPww7VqJV3"
   },
   "source": [
    "**Dropout:**\n",
    "\n",
    "It is also a technique for reducing a overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "paF3N7OopFyK"
   },
   "source": [
    "**Creating Neural Network using layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "baM2mJ2dhIZd"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.3),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vpWnqGFChIeo",
    "outputId": "07a27b9f-29e7-4576-8623-2546f418967e"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XWPC7eqGhN8V"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vQJxKbJHhN_M",
    "outputId": "efbd7841-38e1-4e92-d9d0-890fdeebd2ee"
   },
   "outputs": [],
   "source": [
    "epochs=20\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kaHIlBK9pSy9"
   },
   "source": [
    "Visualize training results:\n",
    "\n",
    "After applying data augmentation and Dropout, there is less overfitting than before, and training and validation accuracy are closer aligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "TVNhgwUYhOCu",
    "outputId": "78768caf-8a5c-4d4f-eb04-f75ad2c5206a"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6t5RPDhqrQo"
   },
   "source": [
    "**Creating a interface for a user to give input** \n",
    "\n",
    "**NOTE** : upload the image file and get a output\n",
    "\n",
    "# **Steps to Run**\n",
    "**Step1 : Run the below section and upload the flower image**\n",
    "\n",
    "**Step2 : Run the next section after image upload.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "IpudDr0qhOF3",
    "outputId": "1c7bb134-e954-44f0-8fd5-36b74cc74fc3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from google.colab import files\n",
    "import keras.utils as image\n",
    "\n",
    "uploaded=files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2QEsSJv9hOJU",
    "outputId": "85c51ee8-3d0a-4d31-dd7f-df197e22971a"
   },
   "outputs": [],
   "source": [
    "for fn in uploaded.keys():\n",
    " \n",
    "  # predicting images\n",
    "  path='/content/' + fn\n",
    "  img=image.load_img(path, target_size=(180, 180))\n",
    "  \n",
    "  x=image.img_to_array(img)\n",
    "  test_img=np.expand_dims(x, axis=0)\n",
    "  \n",
    "  \n",
    "  result = model.predict(test_img)\n",
    "  pred = np.argmax(result) # get the index of max value\n",
    "\n",
    "  if pred == 0:\n",
    "    print(\"Daisy\")\n",
    "  elif pred == 1:\n",
    "    print(\"Dandelion\")\n",
    "  elif pred == 2:\n",
    "    print(\"Rose\")\n",
    "  elif pred == 3:\n",
    "    print(\"Sunflower\")\n",
    "  else:\n",
    "    print(\"Tupil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AcRzAcVzzRec"
   },
   "outputs": [],
   "source": [
    "# its showing correct picture name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJt-TIow6DxO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BhTM2OYJzT08",
    "outputId": "0a38e9dc-9d44-49e9-f9f0-5cd57c227ccd"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "An2Mns775rMl",
    "outputId": "d9ada365-99c9-46c3-976f-e3fd2617d3e6"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "fname = 'ModelName.h5'\n",
    "pickle.dump(model, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGe6ERJ99yRN"
   },
   "source": [
    "# **RESULT :**\n",
    "\n",
    "This project is Done by me with a detailed Analysis and Prediction.The Above model is trained well and getting better accuracy. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "DidqSwAhhOMK"
   },
   "outputs": [],
   "source": [
    "#THANKYOU"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
